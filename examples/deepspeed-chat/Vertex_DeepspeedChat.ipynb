{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db2b959-d545-44bd-a326-9903ed82bbdd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Copyright 2023 Google LLC\n",
    "# \n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "# \n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "# \n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22bca191-3864-471c-becc-bb072adb09c5",
   "metadata": {},
   "source": [
    "# Setup Container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e20825-7406-4fef-9654-7975f6ca44fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Artifact Registry Repo\n",
    "AR_REPO=\"vertex-customjob\"\n",
    "IMG_NAME=\"deepspeed-chat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da293c02-7be8-4559-a2df-10ee42b98192",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID=!gcloud config get-value project\n",
    "PROJECT_ID=PROJECT_ID[0]\n",
    "LOCATION=\"\"\n",
    "BUCKET=\"\"\n",
    "IMAGE_URI=\"us-docker.pkg.dev/{}/{}/{}:latest\".format(PROJECT_ID,AR_REPO,IMG_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e771bc68-e61d-4cce-a7b5-119f3eecfd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ~/vertex-deepspeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c4f5dc-a733-462d-897c-24d17ffa914c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DOCKERFILE=f\"examples/deepspeed-chat/{IMG_NAME}.Dockerfile\"\n",
    "!echo $DOCKERFILE\n",
    "!docker build . -t $IMAGE_URI -f $DOCKERFILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22d05c3-a2b1-4f70-9849-f9dba9414cf9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This test triggers a test run with an example Vertex $CLUSTER_SPEC\n",
    "# It then proceed to deepspeed_train.sh with a single node.\n",
    "TEST_AIP_MODEL_DIR=f\"gs://{BUCKET}/aiplatform-custom-job-xxxx-xx-xx-xx:xx:xx.xxx/model/\"\n",
    "TEST_AIP_TENSORBOARD_LOG_DIR=f\"gs://{BUCKET}/aiplatform-custom-job-xxxx-xx-xx-xx:xx:xx.xxx/logs/\"\n",
    "!docker run \\\n",
    "    --gpus all \\\n",
    "    -e TESTING=\"true\" \\\n",
    "    -e AIP_MODEL_DIR=$TEST_AIP_MODEL_DIR \\\n",
    "    -e AIP_TENSORBOARD_LOG_DIR=$TEST_AIP_TENSORBOARD_LOG_DIR \\\n",
    "    -e MODEL_PATH=\"facebook/opt-125m\" \\\n",
    "    -e DATA_PATHS=\"Dahoas/synthetic-instruct-gptj-pairwise\" \\\n",
    "    -e DATA_SPLIT=\"1,49,50\" \\\n",
    "    -e ZERO_STAGE=\"3\" \\\n",
    "    -e PER_DEVICE_BATCH_SIZE=\"4\" \\\n",
    "$IMAGE_URI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c18bb81-eab9-4851-9de0-aa35234f555b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If this throws error\n",
    "# add \"us-docker.pkg.dev\": \"gcloud\" to /home/jupyter/.docker/config.json\n",
    "!gcloud auth configure-docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12f804e-d987-40a3-87e6-f931bf0ab533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the repo specified in $AR_REPO exists.\n",
    "!echo $IMAGE_URI\n",
    "!docker push $IMAGE_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3583fc-de23-428d-92c7-82fb33153c35",
   "metadata": {},
   "source": [
    "# Test container with aiplatform.CustomJob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94457cc4-ef09-470d-934d-a14189a95300",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from google.cloud import aiplatform\n",
    "\n",
    "aiplatform.init(project=PROJECT_ID, staging_bucket=BUCKET, location=LOCATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e7e084-a6b7-4795-901f-7b081814249c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "######\n",
    "# NOTE: This is an example to test multi-mode training with DeepSpeed on Vertex. \n",
    "#\n",
    "# DeepspeedChat has 3 steps: SFT, Reward Model, and RLHF. We are only calling the SFT step here.\n",
    "# DATA_SPLIT - \"10,40,50\" means 10% of the data is used for SFT. The DeepspeedChat code converts the string into fractions (data_utils.py).\n",
    "#\n",
    "# Testing facebook/opt-125m and Dahoas/synthetic-instruct-gptj-pairwise with 2 1xT4@n1-standard-4:\n",
    "#   PER_DEVICE_BATCH_SIZE - 8 will utilize < half a T4's memory on each of the 2 nodes, 32 uses the memory 70+%\n",
    "#\n",
    "# While the Deepspeed Chat team has auto-tuning on roadmap, if you encounter CUDA OOM right now their advice is:\n",
    "# - Reduce `--per_device_*_batch_size`,\n",
    "# - Increase `--zero_stage {0,1,2,3}` on multi-gpu setups,\n",
    "# - Enable `--gradient_checkpointing` or `--only_optimize_lora`,\n",
    "# - Increase `--gradient_accumulate_steps {#}`, higher number reduces communication of gradients between steps\n",
    "# \n",
    "worker_pool_specs = [\n",
    "    # `WorkerPoolSpec` for worker pool 0, primary replica, required  \n",
    "    {\n",
    "        \"machine_spec\": {\n",
    "            \"machine_type\": \"n1-standard-4\",\n",
    "            \"accelerator_type\": \"NVIDIA_TESLA_T4\",\n",
    "            \"accelerator_count\": 1,       \n",
    "        },\n",
    "        \"replica_count\": 1,\n",
    "        \"container_spec\": {\n",
    "            \"image_uri\": IMAGE_URI,\n",
    "            \"command\": [],\n",
    "            \"args\": [],\n",
    "            \"env\": [\n",
    "                {\"name\": \"MODEL_PATH\", \"value\": \"facebook/opt-125m\"},                        \n",
    "                {\"name\": \"DATA_PATHS\", \"value\": \"Dahoas/synthetic-instruct-gptj-pairwise\"},                        \n",
    "                {\"name\": \"DATA_SPLIT\", \"value\": \"10,40,50\"},\n",
    "                {\"name\": \"ZERO_STAGE\", \"value\": \"3\"},\n",
    "                {\"name\": \"PER_DEVICE_BATCH_SIZE\", \"value\": \"32\"}, \n",
    "            ],                \n",
    "        },\n",
    "        \"disk_spec\": {\n",
    "            \"boot_disk_size_gb\": 1000,            \n",
    "        }\n",
    "    },\n",
    "    {\n",
    "       \"machine_spec\": {\n",
    "            \"machine_type\": \"n1-standard-4\",\n",
    "            \"accelerator_type\": \"NVIDIA_TESLA_T4\",\n",
    "            \"accelerator_count\": 1,           \n",
    "       },\n",
    "       \"replica_count\": 1,        \n",
    "       \"container_spec\": {\n",
    "           \"image_uri\": IMAGE_URI,\n",
    "       },        \n",
    "       \"disk_spec\": {\n",
    "            \"boot_disk_size_gb\": 1000,            \n",
    "       }        \n",
    "    },\n",
    "]\n",
    "\n",
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "JOB_NAME  = \"DeepSpeed Chat Test \" + TIMESTAMP\n",
    "\n",
    "my_job = aiplatform.CustomJob(\n",
    "    display_name=JOB_NAME,    \n",
    "    worker_pool_specs=worker_pool_specs,\n",
    ")\n",
    "\n",
    "# Checking Service account that will launch the job\n",
    "!gcloud config get account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454bf780-ddc1-4795-ac37-2fcb7abedeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####\n",
    "# Either create or reuse a tensorboard\n",
    "# tensorboard = aiplatform.Tensorboard.create(\n",
    "#    display_name=JOB_NAME,\n",
    "# )\n",
    "# \n",
    "# tensorboard_name = \"\"\n",
    "# tensorboard = aiplatform.Tensorboard(tensorboard_name=tensorboard_name)\n",
    "# \n",
    "# print(tensorboard.resource_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6c5133-e0b0-427d-ae81-da5ea8ab5c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# Running the CustomJob\n",
    "#\n",
    "# If custom vpc peering and custom service accounts are desirable, first configure them:\n",
    "#\n",
    "# VPC Peering - https://cloud.google.com/vertex-ai/docs/general/vpc-peering .\n",
    "# Custom Service Account - https://cloud.google.com/vertex-ai/docs/general/custom-service-account \n",
    "#\n",
    "# For custom service account, \n",
    "# be sure to first grant the SA running this notebook the \"Service Account User\" role, \n",
    "# otherwise you won't be able to launch the job with the custom service account.\n",
    "# \n",
    "# Tensorboard - https://cloud.google.com/vertex-ai/docs/experiments/tensorboard-training\n",
    "# Your training script must be configured to write TensorBoard logs to the Cloud Storage bucket, \n",
    "# the location of which the Vertex AI Training Service will automatically make available through \n",
    "# a predefined environment variable AIP_TENSORBOARD_LOG_DIR.\n",
    "#\n",
    "my_job.submit(    \n",
    "    enable_web_access=True, # For debugging\n",
    "    # network=\"projects/{PROJECT_NUMBER}/global/networks/{PEER_NETWORK_NAME}\",\n",
    "    # service_account=\"{CUSTOM_SA_EMAIL}\",\n",
    "    # tensorboard=tensorboard.resource_name,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-13.m110",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-13:m110"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
